{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Telco Churn Prediction using k-NN Algorithm\n",
    "\n",
    "### STEP 1: Import libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect dataset\n",
    "print(\"Shape: \", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "##### Quick observations:\n",
    "1. Mostly categorical features → need encoding.\n",
    "2. Only a few numeric → scaling will be critical for k-NN.\n",
    "3. TotalCharges is wrongly typed → needs cleaning.\n",
    "4. customerID is just an identifier → drop it.\n",
    "5. Dataset size (~7k) is OK for k-NN, but not huge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### STEP 2: DATA PREPROCESSING AND EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "df[\"Churn\"].value_counts(), df[\"Churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column\n",
    "df = df.drop(columns=\"customerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to numeric and fix missing values\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "missing_totalcharges = df[\"TotalCharges\"].isna().sum()\n",
    "print(\"Missing TotalCharges count:\", missing_totalcharges)\n",
    "\n",
    "df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median())\n",
    "\n",
    "print(\"Missing after fill:\", df[\"TotalCharges\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target as binary\n",
    "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "df[\"Churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class balance on target variable\n",
    "df[\"Churn\"].value_counts().plot(kind=\"bar\", title=\"Churn distribution\")\n",
    "plt.xlabel(\"Churn (0=No, 1=Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check numeric feature differences by churn\n",
    "df.groupby(\"Churn\")[[\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and targets\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric vs categorical columns\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"numerical features are: \", num_features)\n",
    "print(\"categorical features (count) are: \", len(cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### STEP 4: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Train churn rate:\", y_train.mean())\n",
    "print(\"Test churn rate:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### STEP 5: Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data preprocessing pipelines for numeric and categorical data\n",
    "# k-NN relies on distance \n",
    "# scaling numeric features is essential. Categorical must be encoded\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessing with ColumnTransformer\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_features),\n",
    "        (\"cat\", cat_pipe, cat_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full model pipeline\n",
    "# object handles end-to-end preprocessing and modeling \n",
    "pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=5, weights=\"distance\"))\n",
    "])\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### STEP 6: Cross-validation baseline (ROC-AUC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model performance reliably on training data using cross-validation\n",
    "cv_auc = cross_val_score(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "print(\"CV ROC-AUC mean:\", cv_auc.mean())\n",
    "print(\"CV ROC-AUC std:\", cv_auc.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### STEP 7: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the training set and evaluate on held-out test data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"Test ROC-AUC:\", test_auc)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
